{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOOLS_ELA\n",
    "\n",
    "*tools_ela.py* is a command line tool that extracts information from original transcribed text. The provided information is:\n",
    "\n",
    "1. Indexes of Words, Lemmas, Types\n",
    "2. Frequencies of Lemmas, Types\n",
    "3. Concordances\n",
    "4. TTR\n",
    "5. Collocations (for both words and lemmas)\n",
    "6. N-grams\n",
    "7. Min, Max and Mean lengths of Types\n",
    "8. POS Tagging (both Bayesian and HMM - Hidden Markov Model)\n",
    "9. TEI attributes (on TEI files)\n",
    "10. TEI entity lists (on TEI files)\n",
    "\n",
    "The tool can handle both *XML-TEI encoded* and pure-text files. By default it handles *XML-TEI*, but a command line argument chan instruct the tool to treat files as text. It is actually a multiplatform tool, actively tested on both Linux and Windows. It works in the current Python *virtual environment*, the same as this Jupyter Lab session.\n",
    "\n",
    "In the same directory as *tools_ela.py* a configuration file is required, namely *tools_ela.cfg*, that specifies working directories. The default configuration is\n",
    "\n",
    "```\n",
    "[Paths]\n",
    "base = .\n",
    "origin_subdir = SOURCE/ela_txt\n",
    "result_subdir = RESULT/tools_ela\n",
    "database = tools_ela.db\n",
    "```\n",
    "\n",
    "Apart from the database, it means that input files are expected to be in `SOURCE/ela_txt` and the results will be written in `RESULT/tools_ela`; the source directory is considered to be *flat*, thus no subdirectories are traversed. Results are stored in a flat directory as well. Result files keep their base prefix and have suffixes such as the following:\n",
    "\n",
    "* `BASEPREFIX_collocations.json`: word collocations\n",
    "* `BASEPREFIX_lemma_collocations.json`: lemma collocations (latin only)\n",
    "* `BASEPREFIX_ngrams.json`: ngrams (at various levels)\n",
    "* `BASEPREFIX_concordances.txt`: concordances (*note: these are text lines*)\n",
    "* `BASEPREFIX_statistics.json`: statistics on the latin part of text\n",
    "* `BASEPREFIX_fulltext_statistics.json`: statistics on all text for all languages\n",
    "* `BASEPREFIX_tei_attrs.json`: data from the XML-TEI header\n",
    "* `BASEPREFIX_tei_lists.json`: lists from XML-TEI encoding (*persName*, *geogName*, *placeName*)\n",
    "\n",
    "All results, except for *concordances*, are in JSON format.\n",
    "\n",
    "**Note:** *tools_ela.py* requires CLTK to be installed, and the `latin_models_cltk` corpus to be loaded. This can be performed from a Python session as follows:\n",
    "\n",
    "```\n",
    ">>> from cltk.corpus.utils.importer import CorpusImporter\n",
    ">>> corpus_importer = CorpusImporter('latin')\n",
    ">>> corpus_importer.import_corpus('latin_models_cltk') \n",
    "```\n",
    "\n",
    "otherwise the tool will exit with a warning. Also, in order to produce data related to *TEI lists* (namely places and people), the *tools_ela.db* has to be present, created from updated dumps of the *Pleiades* and *Geonames* databases. This can be done using the *nbk_dbload* notebook.\n",
    "\n",
    "The following are the command line parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tools_ela.py [-h] [-a] [-C N] [-L N] [-N N] [-O] [-B] [-M] [-T] [-A]\n",
      "                    [-S] [-v] [-p] [--full-monty]\n",
      "                    [BASE_FILENAME]\n",
      "\n",
      "Preprocess latin text file(s) for ELA\n",
      "\n",
      "positional arguments:\n",
      "  BASE_FILENAME         base of filename to process (no directory/extension)\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -a, --all             process all files in the source directory\n",
      "  -C N, --collocations N\n",
      "                        generate collocations file with window up to N\n",
      "                        [N=2..5]\n",
      "  -L N, --lemma-collocations N\n",
      "                        generate lemma collocations file with window up to N\n",
      "                        [N=2..5]\n",
      "  -N N, --ngrams N      generate ngrams file of sizes up to N [N=2..5]\n",
      "  -O, --concordances    generate concordances file\n",
      "  -B, --bayesian-pos    generate bayesian POS tag file\n",
      "  -M, --hmm-pos         generate HMM base POS tag file\n",
      "  -T, --assume-text     assume simple text files instead of XML-TEI\n",
      "  -A, --tei-attrs       generate XML-TEI header attributes file\n",
      "  -S, --tei-lists       generate XML-TEI lists file\n",
      "  -v, --verbose         produce verbose output and timings\n",
      "  -p, --para            include split paragraph data in statistics file\n",
      "  --full-monty          generate MOST files for specified texts\n"
     ]
    }
   ],
   "source": [
    "!python tools_ela.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To invoke the tool for a specific file the `BASE_FILENAME` attribute has to be explicitly specified, *without* extension: extension will be chosen by *tools_ela.py* between *.txt* and *.xml* depending on whether `--assume-text` has been provided or not. To process all files in a directory, just specify `--all`. The `--full-monty` switch is an utility that generates most useful information (actually: everything but *POS tagging*) without having to specify all related command line switches. Thus, for instance, to regenerate POS tagging for *Epistola.xml* in the source directory, issue the following:\n",
    "\n",
    "```\n",
    "$ python tools_ela.py -v -p -M -B Epistola\n",
    "```\n",
    "\n",
    "and to generate most useful information the following command can be launched, as we will do below:\n",
    "\n",
    "```\n",
    "$ python tools_ela.py --full-monty --verbose -a\n",
    "```\n",
    "\n",
    "**Note:** For optimal results this tool should be used on XML-TEI files processed by *RETAG*.\n",
    "\n",
    "The following cell invokes the *tools_ela.py* from the command line, in the above form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sun Mar  1 23:01:48 2020] reading configuration from 'tools_ela.cfg'\n",
      "[Sun Mar  1 23:01:50 2020] notice: assuming input files are in XML-TEI specific format\n",
      "[Sun Mar  1 23:01:50 2020] extracting: statistics\n",
      "[Sun Mar  1 23:01:50 2020] extracting: collocations (window max size: 5)\n",
      "[Sun Mar  1 23:01:50 2020] extracting: lemma_collocations (window max size: 5)\n",
      "[Sun Mar  1 23:01:50 2020] extracting: ngrams (ngram max size: 5)\n",
      "[Sun Mar  1 23:01:50 2020] extracting: concordances\n",
      "[Sun Mar  1 23:01:50 2020] extracting: XML-TEI header attributes\n",
      "[Sun Mar  1 23:01:50 2020] extracting: XML-TEI element lists\n",
      "[Sun Mar  1 23:01:50 2020] starting process for all files\n",
      "[Sun Mar  1 23:01:50 2020] environment:\n",
      "source: 'SOURCE/ela_txt'\n",
      "destination: 'RESULT/tools_ela'\n",
      "[Sun Mar  1 23:01:50 2020] logging errors to: 'error.log'\n",
      "[Sun Mar  1 23:01:50 2020] --- BEGIN ---\n",
      "[Sun Mar  1 23:01:50 2020] --- END ---\n",
      "[Sun Mar  1 23:01:50 2020] process ended: 0 files processed, 0 skipped (0.000 sec)\n"
     ]
    }
   ],
   "source": [
    "!python tools_ela.py --full-monty --verbose -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `RESULT/tools_ela` directory contains all the requested information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
